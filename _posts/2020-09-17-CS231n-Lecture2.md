---
layout: post
title: CS231n 강의 요약 (2) - Image Classification
categories: ["DL"]
tags: ["CS231n"]
---

지난 시간에 배웠던 MIT의 The Summer Vision Project의 목표는 Image Classification이였습니다. 오늘은 Image Classification이 무엇인지, 어떤 방식으로 하는지에 대해 알아보도록 하겠습니다.

<br>

## 1. Image Classification의 목표

![Image Classification](https://drive.google.com/uc?export=view&id=1ivSIoWOsAaHK3eUmQIkFgyQPRP8GZAaO)

우선, Image Classification은 어떤 주어진 사진이 있을 때 그 사진이 무엇을 뜻하는 사진인지 알아맞추는 것입니다.
사람들은 왼쪽에 있는 사진을 보고 [~~떼껄룩~~](https://www.youtube.com/watch?v=9yD7MB3TiA0) 고양이라는 것을 쉽게 알아차릴 수 있죠. 그러나 컴퓨터에게는 그렇지가 않습니다.

![Cat 1](https://drive.google.com/uc?export=view&id=1sUSdt5jFHfDwBcz1p8gu0PdN7pOBrCll)

컴퓨터에 저장된 고양이는 사실 엄청나게 많은 숫자들의 집합입니다. 만약 사진이 600 * 800 사이즈의 RGB 3채널의 이미지라면 600 * 800 * 3짜리 배열입니다.

![Cat 2](https://drive.google.com/uc?export=view&id=1iNrHv2YkD5czInPW_zyUBs1iJ9FK65z3)
![Cats](https://drive.google.com/uc?export=view&id=1iUpUY8zEyBN37lbBRgRyGStHkMlSuAvN)

만약에 고양이가 살짝 움직인 0.5초 뒤에 찍은 사진은 어떨까요? 숫자들의 배열은 **"고양이성"**이 하나도 없기 떄문에 아주 살짝만 움직여도 배열의 숫자들이 전부 바뀝니다.
그렇지만 사람의 눈에는 두 사진은 거의 차이가 없다고 느끼죠. 이렇기 때문에 컴퓨터는 사진을 인식하기가 굉장히 어렵습니다. 이는 같은 고양이를 조금 어두운 장소에서 찍거나,
똑같이 고양이이지만 종이 다른 고양이일 경우, 배경때문에 잘 구분이 안가는 경우, 숨어있는 경우 등등에도 마찬가지로 사진 배열에 저장된 숫자들은 천차만별입니다.

<br>

## 2. Data Driven

![Data Driven](https://drive.google.com/uc?export=view&id=1fs3SX_rABf0wBnEd0VYa7VlRPJFcXc1E)
이러한 이유로 어떤 사진에 대해서 일반적인 알고리즘을 적용하여 그 사진이 어떤 사진인지 판별하기는 굉장히 어렵습니다. 고양이의 예시에서도 고양이가 모두 같은 포즈를 하고있는 것도 아니고, 세상에 고양이가 단 한마리 있는 것도 아니기 때문에 이러한 방식은 사실상 불가능합니다.

그렇기 때문에 등장한 방식이 바로 Data-Driven, 즉 데이터로부터 이끌어낸 방식을 사용하기 시작한 것입니다. 많은 데이터를 수집하여 특정한 방식으로 데이터들을 분류하고 이들을 활용하여 머신러닝 모델을 학습시킬 것 입니다. 이렇게 학습된 모델을 새로운 이미지에 적용하여 이것이 어떤 사진인지 판별하게 하는 것입니다. 이런 방식은 Deep Learning뿐만 아니라 일반적인 머신러닝에서도 통용되는 방식입니다.

<br>

## 3. Nearest Neighbor

![NN](https://drive.google.com/uc?export=view&id=14Osur8K5CdJRiLDYbd761r9HU_g91ggK)

사진들을 분류할 수 있는 Classifier들 중 가장 간단한 방식부터 소개를 하겠습니다. 바로 **Nearest Neighbor**, 직역하면 가장 가까운 이웃입니다. 이름에서 알 수 있듯, 최대한 거리가 가까운 사진들을 모으는 방식으로 가장 간단한 만큼 성능은 좋지 않은 방식입니다.  

사진을 예시로 보면 비스무리하게 생긴 이미지들이 한 분류로 묶여있는 것을 알 수 있습니다. 그러나 실제로 자세히 보면 전혀 다른 이미지가 구도나 배경이 비슷하기 때문에 같은 분류로 묶여있습니다. ~~개구리와 전투기가 같이 묶여있네요..~~ 그렇다면 과연 컴퓨터는 두 사진이 비슷하다는 것을 어떻게 인식할까요?

<br>

![L1](https://drive.google.com/uc?export=view&id=1xm46KwmqY6IH1CeQIKGKYqKoK425cQ5q)

바로 이미지들 사이의 L1 Distance 혹은 Manhattan Distance를 계산하여 이를 비교합니다. 이 Manhattan Distance에 대해서는 조금 뒤에 설명하도록 하겠습니다. 결론적으로는 두 이미지의 같은 위치에 있는 픽셀값의 차이의 절댓값을 전부 더한다는 의미입니다. 이 방식으로는 실제로 두 이미지간의 유사도를 나타내기에는 턱없이 부족하지만 Nearest Neighbor에서는 말 그대로 가장 가까운 이웃들만 골라내기 때문에 사용합니다.

<br>

![L1](https://drive.google.com/uc?export=view&id=1a6fd4eXwUC25BIM6-y2Xc5t165ht7h0z)

이를 실제로 구현한 코드를 보도록 합시다. 가장 먼저 이 방식은 학습할 것이 사실 없습니다. 그저 데이터셋을 불러오는 것이 전부입니다. 그러나 prediction 과정은 다릅니다. 학습과정에서 불러온 전체 데이터셋과 예측할 데이터의 L1 Distance만 구해서 그 중 가장 작은 값을 예측값이라고 하면 되는 것입니다. 그렇기 때문에 데이터셋을 학습시키는 과정은 $$O(1)$$ 이고, 입력값을 예측하는 과정은 $$O(n)$$입니다.

그러나 이 과정은 실제로 사용하기에는 문제가 있습니다. 실제 사용하기 위해선 학습이 오래걸리더라도 예측이 빨라야 하기 때문입니다. 예를 들어 아이폰을 FaceID로 잠금 해제하는데 1분이 걸리면 아무도 사용하지 않을 것 입니다.

<br>

## 4. K-Nearest Neighbor

![knn1](https://drive.google.com/uc?export=view&id=1eksIRjM1_sTVLTn2agmJV5LijESZLHy_)
<p style="opacity: 0.4" > <a href="http://hleecaster.com/ml-knn-concept/"> Reference </a> </p>

이 Nearest Neighbor 알고리즘을 실제로 적용한 것이 바로 K-Nearest Neighbor입니다. 이 알고리즘은 Classification 알고리즘이므로 예측하려고 하는 데이터를 어떻게 분류하는지를 정하는 것이라고 생각하면 되겠습니다.

가장 간단하게 설명하면 어떠한 점을 예측할 때 이 점과 가장 가까운 K개의 이웃들 중 가장 많은 이웃들을 선택하는 알고리즘입니다. 위의 사진의 간단한 예시로는 흰색 점을 빨간색 혹은 초록색 점으로 분류를 해야합니다. 만약 K=1이라면 위의 사진처럼 초록색 점으로 분류가 될 것 입니다.

![knn1](https://drive.google.com/uc?export=view&id=1qrm2A06MtpXuNpTkSGFF1xJ6CSHTTsZK)

만약 K=3이라면, 흰색 점과 가장 가까운 세 개의 점중에 빨간색 점은 1개, 초록색 점은 2개이므로 초록색 점으로 예측하는 것 입니다.

<br>

이 알고리즘에서 중요한 것은 바로 어떻게 점 사이에 거리를 구할 것인가 입니다. 거리를 구하는 방식에 따라서도 결괏값은 매우 달라질 수 있기 떄문입니다. 거리를 구하는 방식은 크게 두 가지, 앞서 언급한 Manhatten Distance(L1 Distance)와 Euclidean Distance(L2 Distance)가 있습니다. 

### 4.1 Manhattan Distance

![L1Dist](https://drive.google.com/uc?export=view&id=1OYkGkZRAhjW07flby6g7sSK3jb-lOqDd)
<p style="opacity: 0.4" > <a href="http://hleecaster.com/ml-distance-formula/"> Reference </a> </p>

먼저 Manhatten Distance부터 살펴보겠습니다. 위에 그림을 보면 점 A와 B사이의 거리를 $$ \vert a_1 - b_1 \vert+\vert a_2 - b_2 \vert $$으로 구하는 방식입니다. "블럭같이 생긴 Manhattan 거리에서의 자동차로 갈 수 있는 최단거리" 에서 따와 Manhattan Distance로 불립니다. 2차원이 아닌 N 차원에서로 일반화 하면 다음과 같습니다.

 $$ \sum_{i=1}^N \vert a_i - b_i\vert$$

 <br>

### 4.2 Euclidean Distance

![L2Dist](https://drive.google.com/uc?export=view&id=1Ai8c5R58ZcbddTf4wRzIcrrIASWapQ-D)

다음 Euclidean Distance입니다. 이번엔 우리가 직관적으로 알고있는 두 점 사이의 거리를 뜻합니다. 위 그림에서 피타고라스 방정식을 이용해 구한 A와 B사이의 Euclidean Distance는$$ \sqrt{ (a_1 - b_1)^2+(a_2 - b_2)^2} $$입니다. 마찬가지로 2차원이 아닌 N차원에서의 거리는 다음과 같이 일반화할 수 있습니다.

$$ \sqrt {\sum_{i=1}^N (a_i - b_i)^2} $$

<br>

![distance](https://drive.google.com/uc?export=view&id=1e_jkl45L4s_-2Th2jyFLV2ADEEcmAwW1)

이 두 거리의 차이점을 나타내면 위의 그림과 같습니다. 두 거리들을 기준으로 원점에서부터 같은 거리에 있는 점들의 집합을 나타내면, 그려지는 그래프가 달라지는 것을 확인할 수 있습니다. 예를 들어 점 $$P(2,2)$$ 에서 원점 $$O$$까지의 Manhattan Distance는 4이지만 Euclidean Distance는 $$2\sqrt{2}$$입니다. 어떤 차이가 있으며 왜 그래프가 저렇게 그려지는지 느낌이 오시나요?

### 4.3 Overfitting & Underfitting

![KNN_K](https://drive.google.com/uc?export=view&id=1C6NCKHEo-ViyMa1wuUtURFMSuO4l5ax5)

또한 이 알고리즘에서 중요한 것은 바로 K값을 정해주는 것입니다. K값은 자신과 가장 가까운 몇명의 이웃들을 볼지를 정해주는 값입니다. 위의 사진을 보면 자신의 분류를 색으로 나타내는 점들을 K값을 변화해가며 K-Nearest Neighbors 알고리즘을 적용해서 분류한 결과입니다.

K=1일 때는 정확도가 100%입니다. 100%이면 좋은것이 아닌가? 라고 생각할 수도 있지만, 이 얘기는 주어진 데이터에 대해서 너무 최적화가 되어있다는 얘기입니다. 다시 말해 주어지지 않은 데이터는 정확하게 판별할 수가 없다는 얘기이고, 이는 알지 못하는 입력을 주어진 데이터셋과 근접하게 예측해야하는 머신러닝의 목적과도 부합하지 않습니다. 이러한 현상을 **Overfitting** 이라고 합니다.

돌아와서 다시 사진을 보면, K=1일 때 초록색 영역사이에 홀로 들어가있는 노란색 점 하나 때문에 초록색 영역 안에 노란색 영역이 생겨버렸습니다. 실제로는 초록색으로 분류되어야 할 것 같은데 말이죠. 또한 파란색 영역에 침범해 있는 일부 빨간점들과 초록점들 때문에 구분된 영역이 고르지 못합니다. 결과적으로 Overfitting이 되어버린 것입니다.

K=3, K=5일 경우에 점점 이러한 문제들이 해결된 것을 알 수 있습니다. 그렇다고 해서 K가 무조건 높을수록 좋은 것은 또 아닙니다. ~~뭐든지 적당히 해야합니다.~~

예를 극단적으로 들어서 K값을 위의 사진에 있는 점의 수로 설정했다고 생각해봅시다. 그렇게 되면 점들 사이의 거리가 의미가 없고 모든 점이 하나의 분류로 묶이게 될 것입니다. 이러한 현상을 Overfitting의 반대인 **Underfitting**이라고 합니다.


## 5. Hyperparameters

![Hyperparam](https://drive.google.com/uc?export=view&id=10sevuDWTul5bUfvqKQxcokvUB3DVbbha)

Hyperparameter란 학습 데이터에서 이끌어 낼 수 있는 값들이 아닌 사용자가 머신러닝 모델을 갱신하는 방법을 지정하는 값들을 얘기합니다. K-Nearest Neighbors 알고리즘에서 중요한 것은 어떠한 거리 공식을 사용할 것인가와 K값을 정하는 것이라고 했습니다. 이 알고리즘에서 거리 공식과 K값과 같은 것들을 **Hyperparameters**라고 합니다.

그렇다면 Hyperparameter들을 어떻게 정할 것이냐가 문제입니다.