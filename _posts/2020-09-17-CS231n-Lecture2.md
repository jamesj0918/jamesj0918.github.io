---
layout: post
title: CS231n 강의 요약 (2) - Image Classification
categories: ["DL"]
tags: ["CS231n"]
---

지난 시간에 배웠던 MIT의 The Summer Vision Project의 목표는 Image Classification이였습니다. 오늘은 Image Classification이 무엇인지, 어떤 방식으로 할 수 있는지 대해 알아보고 간단한 알고리즘인 Nearest Neighbors에 대해서 배워보겠습니다.

<br>

## 1. Image Classification

![Image Classification](https://drive.google.com/uc?export=view&id=1ivSIoWOsAaHK3eUmQIkFgyQPRP8GZAaO)

우선, Image Classification은 어떤 주어진 사진이 있을 때 그 사진이 무엇을 뜻하는 사진인지 알아맞히는 것입니다.
사람들은 왼쪽에 있는 사진을 보고 [~~떼껄룩~~](https://www.youtube.com/watch?v=9yD7MB3TiA0) 고양이라는 것을 쉽게 알아차릴 수 있죠. 그러나 컴퓨터에게는 그렇지가 않습니다.

![Cat 1](https://drive.google.com/uc?export=view&id=1sUSdt5jFHfDwBcz1p8gu0PdN7pOBrCll)

컴퓨터에 저장된 고양이는 사실 엄청나게 많은 숫자들의 집합입니다. 만약 사진이 600 * 800 사이즈의 RGB 3채널의 이미지라면 600 * 800 * 3짜리 배열입니다.

![Cat 2](https://drive.google.com/uc?export=view&id=1iNrHv2YkD5czInPW_zyUBs1iJ9FK65z3)
![Cats](https://drive.google.com/uc?export=view&id=1iUpUY8zEyBN37lbBRgRyGStHkMlSuAvN)

만약에 고양이가 살짝 움직인 0.5초 뒤에 찍은 사진은 어떨까요? 숫자들의 배열은 **"고양이성"**이 하나도 없기 때문에 아주 살짝만 움직여도 배열의 숫자들이 전부 바뀝니다.
그렇지만 사람의 눈에는 두 사진은 거의 차이가 없다고 느끼죠. 이렇기 때문에 컴퓨터는 사진을 인식하기가 굉장히 어렵습니다. 이는 같은 고양이를 조금 어두운 장소에서 찍거나,
똑같이 고양이이지만 종이 다른 고양이일 경우, 배경때문에 잘 구분이 안가는 경우, 숨어있는 경우 등등에도 마찬가지로 사진 배열에 저장된 숫자들은 천차만별입니다.

<br>

## 2. Data Driven

![Data Driven](https://drive.google.com/uc?export=view&id=1fs3SX_rABf0wBnEd0VYa7VlRPJFcXc1E)
이러한 이유로 어떤 사진에 대해서 일반적인 알고리즘을 적용하여 그 사진이 어떤 사진인지 판별하기는 굉장히 어렵습니다. 고양이의 예시에서도 고양이가 모두 같은 포즈를 하고 있는 것도 아니고, 세상에 고양이가 단 한마리 있는 것도 아니기 때문에 이러한 방식은 사실상 불가능합니다.

그렇기 때문에 등장한 방식이 바로 Data-Driven, 즉 데이터로부터 이끌어낸 방식을 사용하기 시작한 것입니다. 많은 데이터를 수집하여 특정한 방식으로 데이터들을 분류하고 이들을 활용하여 머신러닝 모델을 학습시킬 것입니다. 이렇게 학습된 모델을 새로운 이미지에 적용하여 이것이 어떤 사진인지 판별하게 하는 것입니다. 이런 방식은 Deep Learning뿐만 아니라 일반적인 머신러닝에서도 통용되는 방식입니다.

<br>

## 3. Nearest Neighbor

![NN](https://drive.google.com/uc?export=view&id=14Osur8K5CdJRiLDYbd761r9HU_g91ggK)

사진들을 분류할 수 있는 Classifier들 중 가장 간단한 방식부터 소개를 하겠습니다. 바로 **Nearest Neighbor**, 직역하면 가장 가까운 이웃입니다. 이름에서 알 수 있듯, 최대한 거리가 가까운 사진들을 모으는 방식으로 가장 간단한 만큼 성능은 좋지 않은 방식입니다.  

사진을 예시로 보면 비슷비슷하게 생긴 이미지들이 한 분류로 묶여있는 것을 알 수 있습니다. 그러나 실제로 자세히 보면 전혀 다른 이미지가 구도나 배경이 비슷하기 때문에 같은 분류로 묶여있습니다. ~~개구리와 전투기가 같이 묶여있네요..~~ 그렇다면 과연 컴퓨터는 두 사진이 비슷하다는 것을 어떻게 인식할까요?

<br>

![L1](https://drive.google.com/uc?export=view&id=1xm46KwmqY6IH1CeQIKGKYqKoK425cQ5q)

바로 이미지들 사이의 L1 Distance 혹은 Manhattan Distance를 계산하여 이를 비교합니다. 이 Manhattan Distance에 대해서는 조금 뒤에 설명하도록 하겠습니다. 결론적으로는 두 이미지의 같은 위치에 있는 픽셀값의 차이의 절댓값을 전부 더한다는 의미입니다. 이 방식으로는 실제로 두 이미지 간의 유사도를 나타내기에는 턱없이 부족하지만, Nearest Neighbor에서는 말 그대로 가장 가까운 이웃들만 골라내기 때문에 사용합니다.

<br>

![L1](https://drive.google.com/uc?export=view&id=1a6fd4eXwUC25BIM6-y2Xc5t165ht7h0z)

이를 실제로 구현한 코드를 보도록 합시다. 가장 먼저 이 방식은 학습할 것이 사실 없습니다. 그저 데이터셋을 불러오는 것이 전부입니다. 그러나 prediction 과정은 다릅니다. 학습 과정에서 불러온 전체 데이터셋과 예측할 데이터의 L1 Distance만 구해서 그중 가장 작은 값을 예측값이라고 하면 되는 것입니다. 그렇기 때문에 데이터셋을 학습시키는 과정은 $$O(1)$$ 이고, 입력값을 예측하는 과정은 $$O(n)$$입니다.

그러나 이 과정은 실제로 사용하기에는 문제가 있습니다. 실제 사용하기 위해선 학습이 오래 걸리더라도 예측이 빨라야 하기 때문입니다. 예를 들어 아이폰을 FaceID로 잠금 해제하는데 1분이 걸리면 아무도 사용하지 않을 것입니다.

<br>

## 4. K-Nearest Neighbor

![knn1](https://drive.google.com/uc?export=view&id=1eksIRjM1_sTVLTn2agmJV5LijESZLHy_)
<p style="opacity: 0.4" > <a href="http://hleecaster.com/ml-knn-concept/"> Reference </a> </p>

이 Nearest Neighbor 알고리즘을 실제로 적용한 것이 바로 K-Nearest Neighbor입니다. 이 알고리즘은 Classification 알고리즘이므로 예측하려고 하는 데이터를 어떻게 분류하는지를 정하는 것이라고 생각하면 되겠습니다.

가장 간단하게 설명하면 어떠한 점을 예측할 때 이 점과 가장 가까운 K개의 이웃들 중 가장 많은 이웃들을 선택하는 알고리즘입니다. 위의 사진의 간단한 예시로는 흰색 점을 빨간색 혹은 초록색 점으로 분류를 해야 합니다. 만약 K=1이라면 위의 사진처럼 초록색 점으로 분류가 될 것입니다.

![knn1](https://drive.google.com/uc?export=view&id=1qrm2A06MtpXuNpTkSGFF1xJ6CSHTTsZK)

만약 K=3이라면, 흰색 점과 가장 가까운 세 개의 점중에 빨간색 점은 1개, 초록색 점은 2개이므로 초록색 점으로 예측하는 것입니다.

<br>

이 알고리즘에서 중요한 것은 바로 어떻게 점 사이에 거리를 구할 것인가입니다. 거리를 구하는 방식에 따라서도 결괏값은 매우 달라질 수 있기 때문입니다. 거리를 구하는 방식은 크게 두 가지, 앞서 언급한 Manhatten Distance(L1 Distance)와 Euclidean Distance(L2 Distance)가 있습니다. 

### 4.1 Manhattan Distance

![L1Dist](https://drive.google.com/uc?export=view&id=1OYkGkZRAhjW07flby6g7sSK3jb-lOqDd)
<p style="opacity: 0.4" > <a href="http://hleecaster.com/ml-distance-formula/"> Reference </a> </p>

먼저 Manhatten Distance부터 살펴보겠습니다. 위에 그림을 보면 점 A와 B사이의 거리를 $$ \vert a_1 - b_1 \vert+\vert a_2 - b_2 \vert $$으로 구하는 방식입니다. "블록같이 생긴 Manhattan 거리에서의 자동차로 갈 수 있는 최단 거리" 에서 따와 Manhattan Distance로 불립니다. 2차원이 아닌 N 차원으로 일반화하면 다음과 같습니다.

 $$ \sum_{i=1}^N \vert a_i - b_i\vert$$

 <br>

### 4.2 Euclidean Distance

![L2Dist](https://drive.google.com/uc?export=view&id=1Ai8c5R58ZcbddTf4wRzIcrrIASWapQ-D)

다음 Euclidean Distance입니다. 이번엔 우리가 직관적으로 알고 있는 두 점 사이의 거리를 뜻합니다. 위 그림에서 피타고라스 방정식을 이용해 구한 A와 B사이의 Euclidean Distance는$$ \sqrt{ (a_1 - b_1)^2+(a_2 - b_2)^2} $$입니다. 마찬가지로 2차원이 아닌 N차원에서의 거리는 다음과 같이 일반화할 수 있습니다.

$$ \sqrt {\sum_{i=1}^N (a_i - b_i)^2} $$

<br>

![distance](https://drive.google.com/uc?export=view&id=1e_jkl45L4s_-2Th2jyFLV2ADEEcmAwW1)

이 두 거리의 차이점을 나타내면 위의 그림과 같습니다. 두 거리들을 기준으로 원점에서부터 같은 거리에 있는 점들의 집합을 나타내면, 그려지는 그래프가 달라지는 것을 확인할 수 있습니다. 예를 들어 점 $$P(2,2)$$ 에서 원점까지의 Manhattan Distance는 4이지만 Euclidean Distance는 $$2\sqrt{2}$$입니다. 어떤 차이가 있으며 왜 그래프가 저렇게 그려지는지 느낌이 오시나요?

### 4.3 Overfitting & Underfitting

![KNN_K](https://drive.google.com/uc?export=view&id=1C6NCKHEo-ViyMa1wuUtURFMSuO4l5ax5)

또한 이 알고리즘에서 중요한 것은 바로 K값을 정해주는 것입니다. K값은 자신과 가장 가까운 몇 명의 이웃들을 볼지를 정해주는 값입니다. 위의 사진을 보면 자신의 분류를 색으로 나타내는 점들을 K값을 변화해가며 K-Nearest Neighbors 알고리즘을 적용해서 분류한 결과입니다.

K=1일 때는 정확도가 100%입니다. 100%이면 좋은 것이 아닌가? 라고 생각할 수도 있지만, 이 얘기는 주어진 데이터에 대해서 너무 최적화가 되어있다는 얘기입니다. 다시 말해 주어지지 않은 데이터는 정확하게 판별할 수가 없다는 얘기이고, 이는 알지 못하는 입력을 주어진 데이터셋과 근접하게 예측해야 하는 머신러닝의 목적과도 부합하지 않습니다. 이러한 현상을 **Overfitting** 이라고 합니다.

돌아와서 다시 사진을 보면, K=1일 때 초록색 영역 사이에 홀로 들어가있는 노란색 점 하나 때문에 초록색 영역 안에 노란색 영역이 생겨버렸습니다. 실제로는 초록색으로 분류되어야 할 것 같은데 말이죠. 또한, 파란색 영역에 침범해 있는 일부 빨간점들과 초록점들 때문에 구분된 영역이 고르지 못합니다. 결과적으로 Overfitting이 되어버린 것입니다.

K=3, K=5일 경우에 점점 이러한 문제들이 해결된 것을 알 수 있습니다. 그렇다고 해서 K가 무조건 높을수록 좋은 것은 또 아닙니다. ~~뭐든지 적당히 해야 합니다.~~

예를 극단적으로 들어서 K값을 위의 사진에 있는 점의 수로 설정했다고 생각해봅시다. 그렇게 되면 점들 사이의 거리가 의미가 없고 모든 점이 하나의 분류로 묶이게 될 것입니다. 이러한 현상을 Overfitting의 반대인 **Underfitting**이라고 합니다.

### 4.4 Summary

![KNN_ion_image](https://drive.google.com/uc?export=view&id=1NLbkapg0G8KNNspp1UM2SMVu9YWlP8iM)

K-Nearest Neighbors(KNN)에 대해서 알아보았지만, 장점보다는 단점이 훨씬 많았습니다. 실제로 KNN은 이미지에서는 거의 사용하지 않습니다. 앞서 얘기한 예측 시간이 길다는 단점도 있고, 이미지 사이의 관계를 단순하게 픽셀 간 거리를 계산하여 나타나는 것이 적절하지 않다는 것입니다.

위의 4개의 사진을 보면 가장 왼쪽에 있는 원본 이미지를 살짝씩 변형시켜놓은 것입니다. 하지만 실제로 변형한 이미지들과 원본 이미지 사이의 Euclidean Distance를 계산하면, 전부 다 같다는 결론이 나옵니다. 이는 일부러 그렇게 차이가 나도록 조정한 것이지만, 결과적으로는 컴퓨터는 변형한 3개의 사진이 원본 사진과 다른 정도가 같다고 인식을 하는 것이기 때문에 KNN 알고리즘으로 사진을 분류하는 것은 적절하지 않은 것입니다.


<br>

## 5. Hyperparameters

![Hyperparam](https://drive.google.com/uc?export=view&id=10sevuDWTul5bUfvqKQxcokvUB3DVbbha)

Hyperparameter란 학습 데이터에서 이끌어 낼 수 있는 값들이 아닌 사용자가 머신러닝 모델을 갱신하는 방법을 지정하는 값들을 얘기합니다. K-Nearest Neighbors 알고리즘에서 중요한 것은 어떠한 거리 공식을 사용할 것인가와 K값을 정하는 것이라고 했습니다. 이 알고리즘에서 거리 공식과 K값과 같은 것들을 **Hyperparameters**라고 합니다. 그렇다면 hyperparameter들을 어떻게 정할 것이냐가 문제입니다. 실제로 hyperparameter들을 문제마다, 주어진 데이터마다 가장 좋은 값들이 다르기 때문에 일반적으로는 그냥 여러 가지를 시도해 보고 그 중 성능이 가장 hyperparameter들을 골라서 씁니다.

<br>

![Hyperparam1](https://drive.google.com/uc?export=view&id=1rWUbnFx6Da6Jv-TDWj26HUNoLwLUxVya)
![Hyperparam2](https://drive.google.com/uc?export=view&id=1ER5xYUQHyhCIujU9I7B_ySGPvOuu61gK)

그냥 여러 Hyperparameter들을 시도하려고 해도 많은 선택지들이 있습니다.

    1. 데이터셋을 전부 training에 사용한다

    2. 데이터셋을 training 데이터셋과 test 데이터셋으로 나누어서 사용한다.

    3. 데이터셋을 training, validation, test 데이터셋으로 나누어서 사용한다.
    
    4. 데이터셋을 training 데이터셋과 test 데이터셋으로 나누고, training 데이터셋을 여러 개의 folds들로 나누어서 사용한다.

1. 주어진 데이터셋을 전부 사용해서 학습하기 때문에 Overfitting이 일어납니다. 

2. 1번보단 낫지만 결국엔 test set으로 평가한 점수로 hyperparameter들을 정하기 때문에 Overfitting이 일어납니다.

3. 2번과 비슷하지만 validation set으로 hyperparameter들을 정하고 test set은 가장 마지막에 **딱 1번만** 모델을 평가하기 위해서 사용합니다.

4. Deep Learning보다는 작은 크기의 데이터셋에 많이 사용하는 방법입니다. Fold들 중 하나를 validation set으로 생각하고 나머지 fold들을 training set으로 활용합니다. 그렇게 validation set으로 활용할 fold들을 바꿔가며 hyperparameter들을 정하고 마지막에 test set으로 모델을 평가합니다.

<br>

## 6. Summary

이번 강의에서는 머신러닝에 대한 기본적인 개념들을 Nearest Neighbors이라는 간단한 알고리즘을 통해서 알아봤습니다. 사실 저희가 목표로 하는 Image Classification에서는 크게 쓰지 않는 방법이기 때문에 크게 중요한 것은 아니지만 이를 통해서 Overfitting, Underfitting, 머신러닝의 기본적인 컨셉등을 배웠습니다. 실제 강의에서는 Linear Classifier를 살짝 배우면서 마무리 하지만 다음 강의와 연결되는 내용이기 때문에 여기서 마무리하고 다음 강의에서 이어서 포스팅 하겠습니다.

<br>

**세줄 요약**

    1. 컴퓨터에서 사진은 숫자들의 집합이기 때문에 우리가 인식하듯이 컴퓨터가 인식하기가 어렵기 때문에 Data-driven 방식을 활용해서 이미지 분류를 한다.

    2. Nearest Neighbors는 가장 가까운 이웃들에 대한 정보들을 활용해서 분류하는 알고리즘이지만 실제 이미지 분류에 활용하기에는 한계가 있다.

    3. 학습하는 데이터에 의존도가 너무 높아지는 현상을 Overfitting이라고 하며, 이는 머신러닝에서 가장 주의해야 하는 것이다.